---
# heading of document
title: 是谁在唱歌（AuditoryFusion） # Chinese name（English name）
author: 刘楚麒
date: 2018-12-28 # format 2006-01-01
# slug
slug: 08701-auditoryfusion # code-English name
# specific parameters for current task
code: "08701"
sdk: 999
# hugo taxonomy related
tags: 听知觉声音分辨
categories: 文档
# blogdown output
output:
  blogdown::html_page:
    toc: true
    md_extensions: -ascii_identifiers
---

```{r parse-meta, include=FALSE}
NAMES <- strsplit(rmarkdown::metadata$title, "（|）")[[1]]
NAME_CN <- NAMES[1]
NAME_EN <- NAMES[2]
CODE <- rmarkdown::metadata$code
SDK <- rmarkdown::metadata$sdk
```

# 基本信息

* **显示名称**：`r NAME_CN`
* **英文名称**：`r NAME_EN`
* **题目编号**：`r CODE`
* **任务描述**：测查听知觉，特别是声音分辨能力。
* **测查能力**：感知觉-听知觉

# 前端交互

## 基本逻辑

屏幕上呈现一个森林，一左一右分别有一只小鸟，用户被告知两只小鸟会依次发出叫声，之后呈现一个新的声音，要求用户选择该声音更加接近哪只小鸟的叫声，难度会逐渐提高，记录用户的正确率和反应时。

## 详细说明

### 流程说明

每个试次流程如下：

1. 屏幕呈现森林和一左一右两只小鸟。随机一边的小鸟发出声音并有相应动画提示，声音结束500毫秒后另一只小鸟发出声音并有相应动画提示。用户需要记忆这两种声音。
1. 500毫秒后呈现目标刺激，是由左右两边小鸟的声音合成的声音。起始混合比例为75%:25%，75%的为左右**随机**的一侧，后面所有的混合都是如此。随着用户的作答情况，混合比例会发生改变：
    * 若上一个试次用户作答正确，则将上一试次混合比例中较高的减少2.5%（最小为52.5%，下同），而较低的增加2.5%（最大为47.5%，下同）作为本次的混合比例（即难度增加）。
    * 若上一个试次用户作答错误，则将上一试次混合比例中较高的增加2.5%，而较低的减少2.5%作为本次的混合比例（即难度减小）。
1. 等待用户判断该声音更加接近哪只小鸟。一直等待直到用户作出反应。
1. 操作反馈。结束每次反应后立即呈现反馈。
1. 试次间间隔。反馈消失后1s开始下一个试次。

当用户完成8个[轮次](`r blogdown::shortcode("relref", "glossary#轮次")`)（定义二）后结束测验。

### 刺激说明

两只小鸟声音分别去以下网址下载：

* http://sc.chinaz.com/yinxiao/181224558111.htm
* http://sc.chinaz.com/yinxiao/161025485921.htm

分别截取1秒的声音作为原声，之后再两者混合。

# 后台配置

## 数据记录

```{r recording-variables, echo=FALSE, message=FALSE}
knitr::kable(
  readr::read_csv(
    here::here("R", "config", NAME_EN, "recs.csv")
  ),
  caption = "原始数据变量列表"
)
```

## 试题算分

```{r sdk-score, echo=FALSE, message=FALSE}
knitr::kable(
  readr::read_csv(
    here::here("R", "config", NAME_EN, "sdk.csv")
  ),
  caption = paste0("传入参数（算分码：`", SDK, "`）")
)
```
